----------------------------------------------------------------------------------------------------
Namespace(aug_type='subgraph', dataset='cora', drop_percent=0.1, gpu=5, save_name='cora_best_dgi.pkl.pkl', seed=31)
----------------------------------------------------------------------------------------------------
Begin Aug:[subgraph]
Using CUDA
Loss:[0.6931]
Loss:[0.6996]
Loss:[0.6861]
Loss:[0.6905]
Loss:[0.6863]
Loss:[0.6782]
Loss:[0.6766]
Loss:[0.6737]
Loss:[0.6636]
Loss:[0.6587]
Loss:[0.6539]
Loss:[0.6406]
Loss:[0.6350]
Loss:[0.6246]
Loss:[0.6099]
Loss:[0.6024]
Loss:[0.5843]
Loss:[0.5788]
Loss:[0.5599]
Loss:[0.5454]
Loss:[0.5318]
Loss:[0.5144]
Loss:[0.5033]
Loss:[0.4803]
Loss:[0.4733]
Loss:[0.4612]
Loss:[0.4360]
Loss:[0.4331]
Loss:[0.4155]
Loss:[0.3938]
Loss:[0.3847]
Loss:[0.3817]
Loss:[0.3637]
Loss:[0.3501]
Loss:[0.3406]
Loss:[0.3207]
Loss:[0.3146]
Loss:[0.3017]
Loss:[0.2941]
Loss:[0.2827]
Loss:[0.2777]
Loss:[0.2657]
Loss:[0.2608]
Loss:[0.2564]
Loss:[0.2477]
Loss:[0.2400]
Loss:[0.2330]
Loss:[0.2336]
Loss:[0.2268]
Loss:[0.2193]
Loss:[0.2100]
Loss:[0.2075]
Loss:[0.2053]
Loss:[0.2097]
Loss:[0.1969]
Loss:[0.1874]
Loss:[0.2011]
Loss:[0.1752]
Loss:[0.1874]
Loss:[0.1809]
Loss:[0.1713]
Loss:[0.1738]
Loss:[0.1653]
Loss:[0.1539]
Loss:[0.1597]
Loss:[0.1716]
Loss:[0.1563]
Loss:[0.1572]
Loss:[0.1520]
Loss:[0.1532]
Loss:[0.1369]
Loss:[0.1407]
Loss:[0.1399]
Loss:[0.1445]
Loss:[0.1377]
Loss:[0.1358]
Loss:[0.1422]
Loss:[0.1500]
Loss:[0.1287]
Loss:[0.1278]
Loss:[0.1238]
Loss:[0.1251]
Loss:[0.1162]
Loss:[0.1190]
Loss:[0.1171]
Loss:[0.1162]
Loss:[0.1198]
Loss:[0.1126]
Loss:[0.1254]
Loss:[0.0999]
Loss:[0.1137]
Loss:[0.0997]
Loss:[0.1079]
Loss:[0.1165]
Loss:[0.1030]
Loss:[0.1116]
Loss:[0.1152]
Loss:[0.1038]
Loss:[0.0995]
Loss:[0.1182]
Loss:[0.1100]
Loss:[0.0974]
Loss:[0.1079]
Loss:[0.0962]
Loss:[0.0953]
Loss:[0.0973]
Loss:[0.0968]
Loss:[0.0979]
Loss:[0.0833]
Loss:[0.0936]
Loss:[0.0823]
Loss:[0.0990]
Loss:[0.0857]
Loss:[0.0851]
Loss:[0.0850]
Loss:[0.0738]
Loss:[0.0810]
Loss:[0.0760]
Loss:[0.0778]
Loss:[0.0809]
Loss:[0.0673]
Loss:[0.0869]
Loss:[0.0786]
Loss:[0.0770]
Loss:[0.0787]
Loss:[0.0665]
Loss:[0.0766]
Loss:[0.0693]
Loss:[0.0801]
Loss:[0.0828]
Loss:[0.0807]
Loss:[0.0701]
Loss:[0.0801]
Loss:[0.0832]
Loss:[0.0661]
Loss:[0.0685]
Loss:[0.0630]
Loss:[0.0733]
Loss:[0.0683]
Loss:[0.0668]
Loss:[0.0738]
Loss:[0.0665]
Loss:[0.0540]
Loss:[0.0660]
Loss:[0.0625]
Loss:[0.0684]
Loss:[0.0673]
Loss:[0.0719]
Loss:[0.0696]
Loss:[0.0547]
Loss:[0.0532]
Loss:[0.0602]
Loss:[0.0591]
Loss:[0.0574]
Loss:[0.0603]
Loss:[0.0566]
Loss:[0.0720]
Loss:[0.0627]
Loss:[0.0630]
Loss:[0.0612]
Loss:[0.0545]
Loss:[0.0576]
Loss:[0.0546]
Loss:[0.0512]
Loss:[0.0520]
Loss:[0.0512]
Loss:[0.0454]
Loss:[0.0484]
Loss:[0.0548]
Loss:[0.0543]
Loss:[0.0559]
Loss:[0.0528]
Loss:[0.0466]
Loss:[0.0486]
Loss:[0.0492]
Loss:[0.0509]
Loss:[0.0501]
Loss:[0.0448]
Loss:[0.0474]
Loss:[0.0490]
Loss:[0.0444]
Loss:[0.0510]
Loss:[0.0474]
Loss:[0.0422]
Loss:[0.0429]
Loss:[0.0443]
Loss:[0.0447]
Loss:[0.0429]
Loss:[0.0459]
Loss:[0.0471]
Loss:[0.0409]
Loss:[0.0468]
Loss:[0.0370]
Loss:[0.0417]
Loss:[0.0502]
Loss:[0.0513]
Loss:[0.0413]
Loss:[0.0428]
Loss:[0.0444]
Loss:[0.0404]
Loss:[0.0378]
Loss:[0.0427]
Loss:[0.0372]
Loss:[0.0421]
Loss:[0.0346]
Loss:[0.0418]
Loss:[0.0395]
Loss:[0.0391]
Loss:[0.0362]
Loss:[0.0337]
Loss:[0.0378]
Loss:[0.0360]
Loss:[0.0343]
Loss:[0.0352]
Loss:[0.0369]
Loss:[0.0331]
Loss:[0.0370]
Loss:[0.0366]
Loss:[0.0378]
Loss:[0.0334]
Loss:[0.0361]
Loss:[0.0384]
Loss:[0.0372]
Loss:[0.0390]
Loss:[0.0346]
Loss:[0.0343]
Loss:[0.0313]
Loss:[0.0324]
Loss:[0.0352]
Loss:[0.0301]
Loss:[0.0293]
Loss:[0.0254]
Loss:[0.0320]
Loss:[0.0315]
Loss:[0.0323]
Loss:[0.0335]
Loss:[0.0420]
Loss:[0.0322]
Loss:[0.0356]
Loss:[0.0389]
Loss:[0.0301]
Loss:[0.0294]
Loss:[0.0342]
Loss:[0.0295]
Loss:[0.0320]
Loss:[0.0218]
Loss:[0.0361]
Loss:[0.0269]
Loss:[0.0257]
Loss:[0.0320]
Loss:[0.0267]
Loss:[0.0309]
Loss:[0.0265]
Loss:[0.0304]
Loss:[0.0343]
Loss:[0.0323]
Loss:[0.0292]
Loss:[0.0285]
Loss:[0.0309]
Loss:[0.0349]
Loss:[0.0272]
Loss:[0.0269]
Loss:[0.0250]
Loss:[0.0254]
Loss:[0.0251]
Loss:[0.0307]
Early stopping!
Loading 245th epoch
acc:[0.8190]
acc:[0.8190]
acc:[0.8190]
acc:[0.8200]
acc:[0.8190]
acc:[0.8190]
acc:[0.8200]
acc:[0.8170]
acc:[0.8190]
acc:[0.8180]
acc:[0.8200]
acc:[0.8190]
acc:[0.8180]
acc:[0.8200]
acc:[0.8200]
acc:[0.8170]
acc:[0.8210]
acc:[0.8190]
acc:[0.8200]
acc:[0.8200]
acc:[0.8200]
acc:[0.8180]
acc:[0.8180]
acc:[0.8180]
acc:[0.8150]
acc:[0.8170]
acc:[0.8170]
acc:[0.8190]
acc:[0.8160]
acc:[0.8190]
acc:[0.8180]
acc:[0.8180]
acc:[0.8210]
acc:[0.8180]
acc:[0.8180]
acc:[0.8200]
acc:[0.8170]
acc:[0.8200]
acc:[0.8200]
acc:[0.8170]
acc:[0.8200]
acc:[0.8190]
acc:[0.8170]
acc:[0.8170]
acc:[0.8200]
acc:[0.8190]
acc:[0.8160]
acc:[0.8220]
acc:[0.8200]
acc:[0.8200]
----------------------------------------------------------------------------------------------------
Average accuracy:[0.8187]
Mean:[81.8740]
Std :[0.1454]
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
Namespace(aug_type='subgraph', dataset='cora', drop_percent=0.2, gpu=5, save_name='cora_best_dgi.pkl.pkl', seed=31)
----------------------------------------------------------------------------------------------------
Begin Aug:[subgraph]
Using CUDA
Loss:[0.6931]
Loss:[0.6996]
Loss:[0.6861]
Loss:[0.6905]
Loss:[0.6863]
Loss:[0.6782]
Loss:[0.6766]
Loss:[0.6737]
Loss:[0.6636]
Loss:[0.6587]
Loss:[0.6539]
Loss:[0.6406]
Loss:[0.6350]
Loss:[0.6246]
Loss:[0.6099]
Loss:[0.6024]
Loss:[0.5843]
Loss:[0.5788]
Loss:[0.5599]
Loss:[0.5454]
Loss:[0.5318]
Loss:[0.5145]
Loss:[0.5034]
Loss:[0.4803]
Loss:[0.4733]
Loss:[0.4612]
Loss:[0.4360]
Loss:[0.4331]
Loss:[0.4155]
Loss:[0.3938]
Loss:[0.3847]
Loss:[0.3817]
Loss:[0.3637]
Loss:[0.3502]
Loss:[0.3406]
Loss:[0.3207]
Loss:[0.3146]
Loss:[0.3017]
Loss:[0.2941]
Loss:[0.2826]
Loss:[0.2777]
Loss:[0.2657]
Loss:[0.2608]
Loss:[0.2565]
Loss:[0.2477]
Loss:[0.2400]
Loss:[0.2329]
Loss:[0.2336]
Loss:[0.2268]
Loss:[0.2193]
Loss:[0.2099]
Loss:[0.2074]
Loss:[0.2053]
Loss:[0.2097]
Loss:[0.1969]
Loss:[0.1874]
Loss:[0.2010]
Loss:[0.1753]
Loss:[0.1874]
Loss:[0.1808]
Loss:[0.1713]
Loss:[0.1737]
Loss:[0.1653]
Loss:[0.1539]
Loss:[0.1596]
Loss:[0.1715]
Loss:[0.1562]
Loss:[0.1571]
Loss:[0.1519]
Loss:[0.1529]
Loss:[0.1368]
Loss:[0.1408]
Loss:[0.1399]
Loss:[0.1444]
Loss:[0.1376]
Loss:[0.1357]
Loss:[0.1420]
Loss:[0.1498]
Loss:[0.1288]
Loss:[0.1280]
Loss:[0.1237]
Loss:[0.1251]
Loss:[0.1162]
Loss:[0.1188]
Loss:[0.1170]
Loss:[0.1164]
Loss:[0.1197]
Loss:[0.1125]
Loss:[0.1259]
Loss:[0.0999]
Loss:[0.1136]
Loss:[0.0998]
Loss:[0.1079]
Loss:[0.1166]
Loss:[0.1032]
Loss:[0.1116]
Loss:[0.1155]
Loss:[0.1042]
Loss:[0.0995]
Loss:[0.1189]
Loss:[0.1101]
Loss:[0.0979]
Loss:[0.1075]
Loss:[0.0957]
Loss:[0.0954]
Loss:[0.0965]
Loss:[0.0974]
Loss:[0.0976]
Loss:[0.0835]
Loss:[0.0935]
Loss:[0.0821]
Loss:[0.0991]
Loss:[0.0854]
Loss:[0.0857]
Loss:[0.0847]
Loss:[0.0739]
Loss:[0.0809]
Loss:[0.0761]
Loss:[0.0780]
Loss:[0.0808]
Loss:[0.0675]
Loss:[0.0867]
Loss:[0.0785]
Loss:[0.0770]
Loss:[0.0784]
Loss:[0.0666]
Loss:[0.0765]
Loss:[0.0694]
Loss:[0.0800]
Loss:[0.0828]
Loss:[0.0808]
Loss:[0.0701]
Loss:[0.0802]
Loss:[0.0830]
Loss:[0.0663]
Loss:[0.0684]
Loss:[0.0630]
Loss:[0.0732]
Loss:[0.0683]
Loss:[0.0670]
Loss:[0.0738]
Loss:[0.0668]
Loss:[0.0540]
Loss:[0.0663]
Loss:[0.0625]
Loss:[0.0687]
Loss:[0.0674]
Loss:[0.0723]
Loss:[0.0697]
Loss:[0.0547]
Loss:[0.0533]
Loss:[0.0602]
Loss:[0.0593]
Loss:[0.0572]
Loss:[0.0605]
Loss:[0.0564]
Loss:[0.0723]
Loss:[0.0628]
Loss:[0.0633]
Loss:[0.0612]
Loss:[0.0547]
Loss:[0.0577]
Loss:[0.0546]
Loss:[0.0515]
Loss:[0.0519]
Loss:[0.0515]
Loss:[0.0452]
Loss:[0.0487]
Loss:[0.0546]
Loss:[0.0545]
Loss:[0.0558]
Loss:[0.0528]
Loss:[0.0466]
Loss:[0.0487]
Loss:[0.0493]
Loss:[0.0511]
Loss:[0.0502]
Loss:[0.0447]
Loss:[0.0474]
Loss:[0.0490]
Loss:[0.0444]
Loss:[0.0512]
Loss:[0.0475]
Loss:[0.0423]
Loss:[0.0431]
Loss:[0.0444]
Loss:[0.0446]
Loss:[0.0430]
Loss:[0.0459]
Loss:[0.0471]
Loss:[0.0410]
Loss:[0.0469]
Loss:[0.0369]
Loss:[0.0416]
Loss:[0.0502]
Loss:[0.0512]
Loss:[0.0413]
Loss:[0.0428]
Loss:[0.0444]
Loss:[0.0403]
Loss:[0.0377]
Loss:[0.0428]
Loss:[0.0371]
Loss:[0.0422]
Loss:[0.0345]
Loss:[0.0418]
Loss:[0.0394]
Loss:[0.0391]
Loss:[0.0360]
Loss:[0.0335]
Loss:[0.0379]
Loss:[0.0361]
Loss:[0.0343]
Loss:[0.0353]
Loss:[0.0369]
Loss:[0.0331]
Loss:[0.0370]
Loss:[0.0366]
Loss:[0.0378]
Loss:[0.0334]
Loss:[0.0360]
Loss:[0.0384]
Loss:[0.0372]
Loss:[0.0388]
Loss:[0.0345]
Loss:[0.0342]
Loss:[0.0313]
Loss:[0.0324]
Loss:[0.0352]
Loss:[0.0301]
Loss:[0.0294]
Loss:[0.0254]
Loss:[0.0320]
Loss:[0.0315]
Loss:[0.0324]
Loss:[0.0335]
Loss:[0.0420]
Loss:[0.0321]
Loss:[0.0355]
Loss:[0.0388]
Loss:[0.0300]
Loss:[0.0294]
Loss:[0.0342]
Loss:[0.0296]
Loss:[0.0321]
Loss:[0.0218]
Loss:[0.0362]
Loss:[0.0268]
Loss:[0.0258]
Loss:[0.0318]
Loss:[0.0268]
Loss:[0.0309]
Loss:[0.0265]
Loss:[0.0303]
Loss:[0.0342]
Loss:[0.0323]
Loss:[0.0292]
Loss:[0.0285]
Loss:[0.0310]
Loss:[0.0349]
Loss:[0.0272]
Loss:[0.0269]
Loss:[0.0252]
Loss:[0.0254]
Loss:[0.0251]
Loss:[0.0306]
Early stopping!
Loading 245th epoch
acc:[0.8150]
acc:[0.8160]
acc:[0.8170]
acc:[0.8180]
acc:[0.8200]
acc:[0.8200]
acc:[0.8190]
acc:[0.8180]
acc:[0.8170]
acc:[0.8170]
acc:[0.8170]
acc:[0.8180]
acc:[0.8190]
acc:[0.8180]
acc:[0.8170]
acc:[0.8150]
acc:[0.8170]
acc:[0.8180]
acc:[0.8160]
acc:[0.8180]
acc:[0.8190]
acc:[0.8180]
acc:[0.8180]
acc:[0.8170]
acc:[0.8140]
acc:[0.8170]
acc:[0.8190]
acc:[0.8210]
acc:[0.8150]
acc:[0.8200]
acc:[0.8150]
acc:[0.8180]
acc:[0.8200]
acc:[0.8190]
acc:[0.8160]
acc:[0.8190]
acc:[0.8190]
acc:[0.8180]
acc:[0.8160]
acc:[0.8180]
acc:[0.8200]
acc:[0.8170]
acc:[0.8180]
acc:[0.8160]
acc:[0.8160]
acc:[0.8170]
acc:[0.8170]
acc:[0.8190]
acc:[0.8180]
acc:[0.8180]
----------------------------------------------------------------------------------------------------
Average accuracy:[0.8176]
Mean:[81.7640]
Std :[0.1549]
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
Namespace(aug_type='subgraph', dataset='cora', drop_percent=0.4, gpu=5, save_name='cora_best_dgi.pkl.pkl', seed=31)
----------------------------------------------------------------------------------------------------
Begin Aug:[subgraph]
Using CUDA
Loss:[0.6931]
Loss:[0.6996]
Loss:[0.6861]
Loss:[0.6905]
Loss:[0.6863]
Loss:[0.6782]
Loss:[0.6766]
Loss:[0.6737]
Loss:[0.6636]
Loss:[0.6587]
Loss:[0.6539]
Loss:[0.6406]
Loss:[0.6350]
Loss:[0.6246]
Loss:[0.6099]
Loss:[0.6024]
Loss:[0.5843]
Loss:[0.5788]
Loss:[0.5599]
Loss:[0.5454]
Loss:[0.5318]
Loss:[0.5144]
Loss:[0.5033]
Loss:[0.4803]
Loss:[0.4733]
Loss:[0.4612]
Loss:[0.4360]
Loss:[0.4330]
Loss:[0.4155]
Loss:[0.3938]
Loss:[0.3847]
Loss:[0.3817]
Loss:[0.3637]
Loss:[0.3501]
Loss:[0.3406]
Loss:[0.3207]
Loss:[0.3146]
Loss:[0.3016]
Loss:[0.2941]
Loss:[0.2826]
Loss:[0.2776]
Loss:[0.2657]
Loss:[0.2608]
Loss:[0.2564]
Loss:[0.2476]
Loss:[0.2400]
Loss:[0.2329]
Loss:[0.2336]
Loss:[0.2267]
Loss:[0.2192]
Loss:[0.2099]
Loss:[0.2075]
Loss:[0.2053]
Loss:[0.2096]
Loss:[0.1969]
Loss:[0.1874]
Loss:[0.2011]
Loss:[0.1753]
Loss:[0.1874]
Loss:[0.1808]
Loss:[0.1713]
Loss:[0.1738]
Loss:[0.1653]
Loss:[0.1538]
Loss:[0.1596]
Loss:[0.1717]
Loss:[0.1563]
Loss:[0.1571]
Loss:[0.1521]
Loss:[0.1535]
Loss:[0.1368]
Loss:[0.1404]
Loss:[0.1400]
Loss:[0.1446]
Loss:[0.1375]
Loss:[0.1359]
Loss:[0.1425]
Loss:[0.1500]
Loss:[0.1282]
Loss:[0.1276]
Loss:[0.1240]
Loss:[0.1251]
Loss:[0.1163]
Loss:[0.1194]
Loss:[0.1170]
Loss:[0.1157]
Loss:[0.1200]
Loss:[0.1125]
Loss:[0.1244]
Loss:[0.0998]
Loss:[0.1134]
Loss:[0.0992]
Loss:[0.1080]
Loss:[0.1159]
Loss:[0.1024]
Loss:[0.1116]
Loss:[0.1138]
Loss:[0.1028]
Loss:[0.0989]
Loss:[0.1164]
Loss:[0.1105]
Loss:[0.0959]
Loss:[0.1094]
Loss:[0.0986]
Loss:[0.0953]
Loss:[0.1007]
Loss:[0.0956]
Loss:[0.0989]
Loss:[0.0831]
Loss:[0.0937]
Loss:[0.0831]
Loss:[0.0988]
Loss:[0.0871]
Loss:[0.0838]
Loss:[0.0853]
Loss:[0.0740]
Loss:[0.0809]
Loss:[0.0763]
Loss:[0.0777]
Loss:[0.0814]
Loss:[0.0667]
Loss:[0.0872]
Loss:[0.0789]
Loss:[0.0769]
Loss:[0.0791]
Loss:[0.0664]
Loss:[0.0768]
Loss:[0.0691]
Loss:[0.0803]
Loss:[0.0829]
Loss:[0.0808]
Loss:[0.0703]
Loss:[0.0801]
Loss:[0.0834]
Loss:[0.0658]
Loss:[0.0686]
Loss:[0.0629]
Loss:[0.0733]
Loss:[0.0683]
Loss:[0.0668]
Loss:[0.0739]
Loss:[0.0665]
Loss:[0.0540]
Loss:[0.0661]
Loss:[0.0626]
Loss:[0.0684]
Loss:[0.0673]
Loss:[0.0720]
Loss:[0.0695]
Loss:[0.0546]
Loss:[0.0531]
Loss:[0.0602]
Loss:[0.0591]
Loss:[0.0572]
Loss:[0.0602]
Loss:[0.0565]
Loss:[0.0722]
Loss:[0.0627]
Loss:[0.0631]
Loss:[0.0611]
Loss:[0.0545]
Loss:[0.0576]
Loss:[0.0546]
Loss:[0.0513]
Loss:[0.0519]
Loss:[0.0512]
Loss:[0.0453]
Loss:[0.0485]
Loss:[0.0547]
Loss:[0.0543]
Loss:[0.0558]
Loss:[0.0528]
Loss:[0.0466]
Loss:[0.0487]
Loss:[0.0493]
Loss:[0.0509]
Loss:[0.0500]
Loss:[0.0446]
Loss:[0.0474]
Loss:[0.0489]
Loss:[0.0444]
Loss:[0.0511]
Loss:[0.0474]
Loss:[0.0422]
Loss:[0.0430]
Loss:[0.0443]
Loss:[0.0446]
Loss:[0.0429]
Loss:[0.0459]
Loss:[0.0471]
Loss:[0.0410]
Loss:[0.0469]
Loss:[0.0369]
Loss:[0.0416]
Loss:[0.0502]
Loss:[0.0512]
Loss:[0.0413]
Loss:[0.0428]
Loss:[0.0444]
Loss:[0.0402]
Loss:[0.0377]
Loss:[0.0426]
Loss:[0.0371]
Loss:[0.0421]
Loss:[0.0345]
Loss:[0.0417]
Loss:[0.0394]
Loss:[0.0391]
Loss:[0.0361]
Loss:[0.0335]
Loss:[0.0378]
Loss:[0.0361]
Loss:[0.0342]
Loss:[0.0351]
Loss:[0.0368]
Loss:[0.0331]
Loss:[0.0370]
Loss:[0.0366]
Loss:[0.0377]
Loss:[0.0333]
Loss:[0.0360]
Loss:[0.0383]
Loss:[0.0371]
Loss:[0.0388]
Loss:[0.0346]
Loss:[0.0344]
Loss:[0.0313]
Loss:[0.0324]
Loss:[0.0353]
Loss:[0.0301]
Loss:[0.0294]
Loss:[0.0254]
Loss:[0.0320]
Loss:[0.0315]
Loss:[0.0323]
Loss:[0.0334]
Loss:[0.0421]
Loss:[0.0322]
Loss:[0.0355]
Loss:[0.0388]
Loss:[0.0301]
Loss:[0.0293]
Loss:[0.0342]
Loss:[0.0295]
Loss:[0.0320]
Loss:[0.0217]
Loss:[0.0363]
Loss:[0.0268]
Loss:[0.0258]
Loss:[0.0319]
Loss:[0.0267]
Loss:[0.0308]
Loss:[0.0265]
Loss:[0.0303]
Loss:[0.0342]
Loss:[0.0323]
Loss:[0.0292]
Loss:[0.0285]
Loss:[0.0310]
Loss:[0.0349]
Loss:[0.0272]
Loss:[0.0271]
Loss:[0.0250]
Loss:[0.0254]
Loss:[0.0251]
Loss:[0.0306]
Early stopping!
Loading 245th epoch
acc:[0.8160]
acc:[0.8150]
acc:[0.8150]
acc:[0.8170]
acc:[0.8170]
acc:[0.8150]
acc:[0.8170]
acc:[0.8150]
acc:[0.8180]
acc:[0.8170]
acc:[0.8160]
acc:[0.8160]
acc:[0.8200]
acc:[0.8200]
acc:[0.8150]
acc:[0.8170]
acc:[0.8190]
acc:[0.8190]
acc:[0.8150]
acc:[0.8180]
acc:[0.8160]
acc:[0.8160]
acc:[0.8210]
acc:[0.8170]
acc:[0.8130]
acc:[0.8190]
acc:[0.8140]
acc:[0.8170]
acc:[0.8150]
acc:[0.8180]
acc:[0.8120]
acc:[0.8180]
acc:[0.8160]
acc:[0.8200]
acc:[0.8150]
acc:[0.8170]
acc:[0.8200]
acc:[0.8180]
acc:[0.8150]
acc:[0.8160]
acc:[0.8200]
acc:[0.8160]
acc:[0.8150]
acc:[0.8150]
acc:[0.8150]
acc:[0.8140]
acc:[0.8140]
acc:[0.8190]
acc:[0.8160]
acc:[0.8190]
----------------------------------------------------------------------------------------------------
Average accuracy:[0.8167]
Mean:[81.6660]
Std :[0.2047]
----------------------------------------------------------------------------------------------------
